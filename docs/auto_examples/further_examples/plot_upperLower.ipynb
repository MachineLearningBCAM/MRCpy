{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Example: Use of Upper and Lower bound as error estimation\n\nThis example is an extension to `ex2` where we will prove how the upper and lower\nbound of the loss are an unbiased estimator of the error. The models are trained \nwith different number of cases ranging from 10% to 80% of the data and then are\ntested with 20% of the samples. The graphs show how in most of the cases \nthe error is between those bounds which proves the potential of this feature of\nthe MRCs. The results are for a :mod:`MRC(phi = 'fourier', loss = '0-1', s = 1)`\n\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Note that there is an additional dataset related to COVID-19 patients\n             that is available upon requesting to HM Hospitales `here <https://www.hmhospitales.com/coronavirus/covid-data-save-lives/english-version>`_  .\n             More information about this dataset can be found in the `COVID example<ex_covid>`</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import needed modules\nimport pandas as pd\nimport numpy as np\nimport time\nimport tabulate \n\n# sklearn\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n# SMOTE over-sampling \nfrom imblearn.over_sampling import SMOTE\n\n#MRCpy\nfrom MRCpy import MRC,CMRC\n\n# Data visualisation\n\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\nsns.set_context(\"paper\")\nimport matplotlib.pyplot as plt\n\n\ndef load_covid(norm = False, array = True ):\n    data_consensus = pd.read_csv(\"data/data_consensus.csv\", sep=\";\")\n\n    variable_dict = {'CD0000AGE': 'Age', 'CORE': 'PATIENT_ID', 'CT000000U': 'Urea',\n                     'CT00000BT': 'Bilirubin', 'CT00000NA': 'Sodium', \n                     'CT00000TP': 'Proth_time', 'CT0000COM': 'Com', \n                     'CT0000LDH': 'LDH', 'CT0000NEU': 'Neutrophils', \n                     'CT0000PCR': 'Pro_C_Rea', 'CT0000VCM': 'Med_corp_vol', \n                     'CT000APTT': 'Ceph_time','CT000CHCM': 'Mean_corp_Hgb',\n                     'CT000EOSP': 'Eosinophils%', 'CT000LEUC': 'Leukocytes',\n                     'CT000LINP': 'Lymphocytes%', 'CT000NEUP': 'Neutrophils%',\n                     'CT000PLAQ': 'Platelet_count', 'CTHSDXXRATE': 'Rate',\n                     'CTHSDXXSAT': 'Sat', 'ED0DISWHY': 'Status',\n                     'F_INGRESO/ADMISSION_D_ING/INPAT': 'Fecha_admision',\n                     'SEXO/SEX': 'Sexo'}\n    data_consensus = data_consensus.rename(columns=variable_dict)\n    if norm:\n        x_consensus = data_consensus[data_consensus.columns.difference(\n            ['Status', 'PATIENT_ID'])][:]\n        std_scale = preprocessing.StandardScaler().fit(x_consensus)\n        x_consensus_std = std_scale.transform(x_consensus)\n        dataframex_consensus = pd.DataFrame(\n            x_consensus_std, columns=x_consensus.columns)\n        data_consensus.reset_index(drop=True, inplace=True)\n        data_consensus = pd.concat(\n            [dataframex_consensus, data_consensus[[\"Status\"]]], axis=1)\n\n    data_consensus = data_consensus[data_consensus.columns.difference([\n                                                                      'PATIENT_ID'])]\n    X = data_consensus[data_consensus.columns.difference(\n        ['Status', 'PATIENT_ID'])]\n    y = data_consensus['Status']\n    if array:\n        X = X.to_numpy()\n        y = y.to_numpy()\n    return X,y\ndef getUpperLowerdf(train_size, X, y , cv, paramsMRC, smote = True):\n    '''\n    Parameters\n    ----------\n    train_size : array\n        Array of different training sizes to train the model.\n    cv : CrossValidator\n        Cross validator.\n    paramsMRC : TYPE\n        Parameters for the MRCs.\n    smote : Bool, optional\n        Class imbalance corrector, set to false to disable. The default is True.\n    Returns\n    -------\n    table : dataFrame\n        Dataframe with the results of the training for each training size.\n\n    '''\n    if smote:\n        smotefit = SMOTE(sampling_strategy='auto')\n        X, y = smotefit.fit_resample(X, y)\n    table = pd.DataFrame()\n    for train_set in train_size:\n        for j, (train_index, test_index) in enumerate(cv.split(X, y)):\n            X_train, X_test = X[train_index], X[test_index]\n            y_train, y_test = y[train_index], y[test_index]\n            \n            random_indices = np.random.choice(X_train.shape[0], size=int(X.shape[0]*train_set), replace=False)\n            X_train = X_train[random_indices,:]\n            y_train = y_train[random_indices]\n            std_scale = preprocessing.StandardScaler().fit(X_train, y_train)\n            X_train = std_scale.transform(X_train)\n            X_test = std_scale.transform(X_test)\n            start_time = time.time()\n            MRC_model = MRC(phi='fourier', s =1, **paramsMRC).fit(X_train, y_train)\n            train_time = time.time()-start_time\n            auxtable = pd.DataFrame(columns = ['Error','Upper', 'Lower', 'iteration', 'train_size', 'Time'], index = range(0,1))\n            auxtable['train_size'] = train_set\n            auxtable['iteration'] = j\n            auxtable['Error'] = 1-MRC_model.score(X_test,y_test)\n            auxtable['Time'] = train_time\n            auxtable['Upper'] = MRC_model.get_upper_bound()\n            auxtable['Lower'] = MRC_model.get_lower_bound()\n\n            table = table.append(auxtable, ignore_index = True)\n    return table\n\n# Import the datasets\nfrom MRCpy.datasets import *\n# Data sets\nloaders = [load_mammographic, load_haberman, load_indian_liver,\n           load_diabetes, load_credit, load_covid]\ndataName = [\"mammographic\", \"haberman\", \"indian_liver\",\n            \"diabetes\", \"credit\",'COVID']\nparamsMRC = {'deterministic': False,'fit_intercept': False, 'use_cvx': True, 'loss': '0-1'}\ntrain = np.arange(0.1,0.81,0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross test validation\n5 fold repeated Stratified Cross validation is performed where each of the \nfold is trained with 80% of the data and then tested with the remaining 20%\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_splits = 5\nn_repeats = 10\ncv = RepeatedStratifiedKFold(n_splits=n_splits,n_repeats =n_repeats, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results\nWe will present the results for the 6 datasets. For more information \nabout the dataset refer to the `MRCpy documentation <https://machinelearningbcam.github.io/MRCpy/getting_started.html#dataset-loaders>`_ of the loaders.\nIn the results we can see how the upper and lower bounds get closer when the training \nsize is increased. Furthermore, the standard deviation of both bounds is reduced significantly. \n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mammographic\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, y = load_mammographic()\ntable = getUpperLowerdf(train, X, y, cv, paramsMRC)\n# dataframes.append(table)\n# plotUpperLower(table)\nmeans = table[table.columns.difference(['iteration'])].groupby('train_size').mean()\nstd = table[table.columns.difference(['iteration'])].groupby('train_size').std()\nfor column in means.columns:\n    means[column] = means[column].round(3).astype(str) + ' \u00b1 ' +std[column].round(3).astype(str)\nmeans[['Error','Upper','Lower', 'Time']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nsns.lineplot(data = table,x ='train_size', y = 'Error', label = 'Test Error', ax = ax)\nsns.lineplot(data = table,x ='train_size', y = 'Upper', color = 'red', label = 'Upper bound', linestyle = 'dotted', ax = ax)\nsns.lineplot(data = table,x ='train_size', y = 'Lower', color = 'green', label = 'Lower bound',  linestyle = 'dotted', ax = ax)\nplt.suptitle('Mammographic')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Haberman\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, y = load_haberman()\ntable = getUpperLowerdf(train, X, y, cv, paramsMRC)\nmeans = table[table.columns.difference(['iteration'])].groupby('train_size').mean()\nstd = table[table.columns.difference(['iteration'])].groupby('train_size').std()\nfor column in means.columns:\n    means[column] = means[column].round(3).astype(str) + ' \u00b1 ' +std[column].round(3).astype(str)\nmeans[['Error','Upper','Lower', 'Time']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nsns.lineplot(data = table,x ='train_size', y = 'Error', label = 'Test Error', ax = ax)\nsns.lineplot(data = table,x ='train_size', y = 'Upper', color = 'red', label = 'Upper bound', linestyle = 'dotted', ax = ax)\nsns.lineplot(data = table,x ='train_size', y = 'Lower', color = 'green', label = 'Lower bound',  linestyle = 'dotted', ax = ax)\nplt.suptitle('Haberman')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Indian liver\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, y = load_indian_liver()\n\ntable = getUpperLowerdf(train, X, y, cv, paramsMRC)\nmeans = table[table.columns.difference(['iteration'])].groupby('train_size').mean()\nstd = table[table.columns.difference(['iteration'])].groupby('train_size').std()\nfor column in means.columns:\n    means[column] = means[column].round(3).astype(str) + ' \u00b1 ' +std[column].round(3).astype(str)\nmeans[['Error','Upper','Lower', 'Time']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nsns.lineplot(data = table,x ='train_size', y = 'Error', label = 'Test Error', ax = ax)\nsns.lineplot(data = table,x ='train_size', y = 'Upper', color = 'red', label = 'Upper bound', linestyle = 'dotted', ax = ax)\nsns.lineplot(data = table,x ='train_size', y = 'Lower', color = 'green', label = 'Lower bound',  linestyle = 'dotted', ax = ax)\nplt.suptitle('Indian Liver')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## diabetes\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, y = load_diabetes()\n\ntable = getUpperLowerdf(train, X, y, cv, paramsMRC)\nmeans = table[table.columns.difference(['iteration'])].groupby('train_size').mean()\nstd = table[table.columns.difference(['iteration'])].groupby('train_size').std()\nfor column in means.columns:\n    means[column] = means[column].round(3).astype(str) + ' \u00b1 ' +std[column].round(3).astype(str)\nmeans[['Error','Upper','Lower', 'Time']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nsns.lineplot(data = table,x ='train_size', y = 'Error', label = 'Test Error', ax = ax)\nsns.lineplot(data = table,x ='train_size', y = 'Upper', color = 'red', label = 'Upper bound', linestyle = 'dotted', ax = ax)\nsns.lineplot(data = table,x ='train_size', y = 'Lower', color = 'green', label = 'Lower bound',  linestyle = 'dotted', ax = ax)\nplt.suptitle('Diabetes')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## credit\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, y = load_credit()\n\ntable = getUpperLowerdf(train, X, y, cv, paramsMRC)\nmeans = table[table.columns.difference(['iteration'])].groupby('train_size').mean()\nstd = table[table.columns.difference(['iteration'])].groupby('train_size').std()\nfor column in means.columns:\n    means[column] = means[column].round(3).astype(str) + ' \u00b1 ' +std[column].round(3).astype(str)\nmeans[['Error','Upper','Lower', 'Time']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nsns.lineplot(data = table,x ='train_size', y = 'Error', label = 'Test Error', ax = ax)\nsns.lineplot(data = table,x ='train_size', y = 'Upper', color = 'red', label = 'Upper bound', linestyle = 'dotted', ax = ax)\nsns.lineplot(data = table,x ='train_size', y = 'Lower', color = 'green', label = 'Lower bound',  linestyle = 'dotted', ax = ax)\nplt.suptitle('Credit')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## COVID\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, y = load_covid()\n\ntable = getUpperLowerdf(train, X, y, cv, paramsMRC)\nmeans = table[table.columns.difference(['iteration'])].groupby('train_size').mean()\nstd = table[table.columns.difference(['iteration'])].groupby('train_size').std()\nfor column in means.columns:\n    means[column] = means[column].round(3).astype(str) + ' \u00b1 ' +std[column].round(3).astype(str)\nmeans[['Error','Upper','Lower', 'Time']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nsns.lineplot(data = table,x ='train_size', y = 'Error', label = 'Test Error', ax = ax)\nsns.lineplot(data = table,x ='train_size', y = 'Upper', color = 'red', label = 'Upper bound', linestyle = 'dotted', ax = ax)\nsns.lineplot(data = table,x ='train_size', y = 'Lower', color = 'green', label = 'Lower bound',  linestyle = 'dotted', ax = ax)\nplt.suptitle('COVID')\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}