
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_example2.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_example2.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_example2.py:


.. _ex2:

Example: Use of CMRC with different settings
============================================

Example of using CMRC with some of the common classification datasets with
different losses and feature mappings settings. We load the different datasets
and use 10-Fold Cross-Validation to generate the partitions for train and test.
We separate 1 partition each time for testing and use the others for training.
On each iteration we calculate
the classification error. We also calculate the mean training time.

You can check a more elaborated example in :ref:`ex_comp`.

.. GENERATED FROM PYTHON SOURCE LINES 17-114




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    *** Example (CMRC with the additional     marginal constraints) *** 


    1. Using 0-1 loss and relu feature mapping 


     ############## 
     mammographic n= 961 , d= 5, cardY= 2
     error= : 0.17789948453608245 +/- 0.03566906436986172
     avg_train_time= : 83.6018925666809 secs
     ############## 


     ############## 
     haberman n= 306 , d= 3, cardY= 2
     error= : 0.25860215053763447 +/- 0.03425115185844817
     avg_train_time= : 7.806287407875061 secs
     ############## 


     ############## 
     indian_liver n= 583 , d= 10, cardY= 2
     error= : 0.28997662185856227 +/- 0.03552377873248201
     avg_train_time= : 28.09897572994232 secs
     ############## 


     ############## 
     diabetes n= 768 , d= 8, cardY= 2
     error= : 0.2460868079289132 +/- 0.033040281294701435
     avg_train_time= : 48.85894320011139 secs
     ############## 


     ############## 
     credit n= 690 , d= 15, cardY= 2
     error= : 0.14057971014492754 +/- 0.0425257992786122
     avg_train_time= : 35.96012754440308 secs
     ############## 


    2. Using log loss and relu feature mapping 


     ############## 
     mammographic n= 961 , d= 5, cardY= 2
     error= : 0.17794243986254293 +/- 0.03740768372063
     avg_train_time= : 9.726464366912841 secs
     ############## 


     ############## 
     haberman n= 306 , d= 3, cardY= 2
     error= : 0.2587096774193548 +/- 0.05974122327853731
     avg_train_time= : 1.9104907512664795 secs
     ############## 


     ############## 
     indian_liver n= 583 , d= 10, cardY= 2
     error= : 0.28118059614260665 +/- 0.03150871350737739
     avg_train_time= : 4.516436839103699 secs
     ############## 


     ############## 
     diabetes n= 768 , d= 8, cardY= 2
     error= : 0.23438140806561852 +/- 0.0427392439807677
     avg_train_time= : 6.675226426124572 secs
     ############## 


     ############## 
     credit n= 690 , d= 15, cardY= 2
     error= : 0.136231884057971 +/- 0.04592167976160829
     avg_train_time= : 5.496482157707215 secs
     ############## 








|

.. code-block:: default


    import time

    import numpy as np
    from sklearn import preprocessing
    from sklearn.model_selection import StratifiedKFold

    from MRCpy import CMRC
    # Import the datasets
    from MRCpy.datasets import *

    # Data sets
    loaders = [load_mammographic, load_haberman, load_indian_liver,
               load_diabetes, load_credit]
    dataName = ["mammographic", "haberman", "indian_liver",
                "diabetes", "credit"]


    def runCMRC(phi, loss):

        res_mean = np.zeros(len(dataName))
        res_std = np.zeros(len(dataName))

        # We fix the random seed to that the stratified kfold performed
        # is the same through the different executions
        random_seed = 0

        # Iterate through each of the dataset and fit the CMRC classfier.
        for j, load in enumerate(loaders):

            # Loading the dataset
            X, Y = load(return_X_y=True)
            r = len(np.unique(Y))
            n, d = X.shape

            # Print the dataset name
            print(" ############## \n " + dataName[j] + " n= " + str(n) +
                  " , d= " + str(d) + ", cardY= " + str(r))

            # Create the CMRC object initilized with the corresponding parameters
            clf = CMRC(phi=phi, loss=loss, use_cvx=True,
                       solver='MOSEK', max_iters=10000, s=0.3)

            # Generate the partitions of the stratified cross-validation
            cv = StratifiedKFold(n_splits=10, random_state=random_seed,
                                 shuffle=True)

            cvError = list()
            auxTime = 0

            # Paired and stratified cross-validation
            for train_index, test_index in cv.split(X, Y):

                X_train, X_test = X[train_index], X[test_index]
                y_train, y_test = Y[train_index], Y[test_index]

                # Normalizing the data
                std_scale = preprocessing.StandardScaler().fit(X_train, y_train)
                X_train = std_scale.transform(X_train)
                X_test = std_scale.transform(X_test)

                # Save start time for computing training time
                startTime = time.time()

                # Train the model
                clf.fit(X_train, y_train)

                # Save the training time
                auxTime += time.time() - startTime

                # Predict the class for test instances
                y_pred = clf.predict(X_test)

                # Calculate the error made by CMRC classificator
                cvError.append(np.average(y_pred != y_test))

            res_mean[j] = np.average(cvError)
            res_std[j] = np.std(cvError)

            # Calculating the mean training time
            auxTime = auxTime / 10

            print(" error= " + ": " + str(res_mean[j]) + " +/- " +
                  str(res_std[j]) + "\n avg_train_time= " + ": " +
                  str(auxTime) + ' secs' + "\n ############## \n\n")


    if __name__ == '__main__':

        print('*** Example (CMRC with the additional\
         marginal constraints) *** \n\n')

        print('1. Using 0-1 loss and relu feature mapping \n\n')
        runCMRC(phi='relu', loss='0-1')

        print('2. Using log loss and relu feature mapping \n\n')
        runCMRC(phi='relu', loss='log')


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 38 minutes  47.119 seconds)


.. _sphx_glr_download_auto_examples_plot_example2.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_example2.py <plot_example2.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_example2.ipynb <plot_example2.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
