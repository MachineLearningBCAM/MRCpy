{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# MRCs with Deep Neural Networks: Part II\nIn this example we will use a features extracted from different sets of images\nusing pretrained neural networks, as explained in `featureextraction`.\n\nWe will use image features correponding to a set of training images to train an\nMRC model to then predict the class of a set of test images using their\ncorreponding extracted features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split\n\nfrom MRCpy import MRC\nfrom MRCpy.datasets import (\n    load_catsvsdogs_features_resnet18,\n    load_mnist_features_resnet18,\n    load_yearbook_features_resnet18)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MNIST Dataset: Digit Recognizer\nThe MNIST database of handwritten digits, available from\n`this page<http://yann.lecun.com/exdb/mnist/>`,\nhas a training set of 60000 examples, and a test set of 10000 examples. All\nimages have dimension (28,28,1) and they are greyscale.\nWe are using a set of 512 features extracted from each image using a\npretrained neural network as explained in `featureextraction`.\n\nWe are performing binary classification, training a model to distinguish\nbetween two digits. We choose classification between 6 & 8.\n\nWe compare our results with the article `\"A Poor Example of Transfer\nLearning: Applying VGG Pre-trained model with Keras\"\n<https://bit.ly/3g2Ymv3>`_\nwhere they perform\nthis same task with a different pretrained network (VGG) and a different\nclassification algorithm (logistic regression) obtaining poor results:\naccuracy of 50.2%, which is really similar to juust random guessing. This\nshows that using any classification algorithm over features extracted with\na pretrained model does not always work good. They also replicate the\nbinary classification problem using logistic regression directly over\nMNIST raw data and obtain accuracy of 98.71%.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = load_mnist_features_resnet18(split=True)\n\nidx_binary_train = np.logical_or(Y_train == 6, Y_train == 8)\nidx_binary_test = np.logical_or(Y_test == 6, Y_test == 8)\n\nX_train_binary = X_train[idx_binary_train]\nX_test_binary = X_test[idx_binary_test]\nY_train_binary = Y_train[idx_binary_train]\nY_test_binary = Y_test[idx_binary_test]\n\nclf = MRC(phi='linear').fit(X_train_binary, Y_train_binary)\nY_pred = clf.predict(X_test_binary)\nerror = np.average(Y_pred != Y_test_binary)\naccuracy = 1 - error\nprint('MNIST Binary Classification (6 vs. 8) accuracy error: '\n      + '%2.2f' % (accuracy * 100) + '%')\ncm = confusion_matrix(Y_test_binary, Y_pred)\ncm_display = ConfusionMatrixDisplay(cm, display_labels=['6', '8']).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cats vs Dogs Dataset\nCats vs dogs dataset is a database of 23262 RGB cats\nand dogs images released by Microsoft for the Asirra captcha (`homepage\n<https://www.microsoft.com/en-us/download/details.aspx?id=54765>`_).\nCats are labeled by 0 and dogs by 1 and there are 11658 and 11604 images\nof each class, respectively. We are using the features extracted using\na pretrained ResNet18 netowork over ImageNet.\n\nFor comparison purposes, in this tutorial they obtain accuracy of 97% for\nthis task using a pretrained VGG16 network together with some more deep\nneural layers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, Y = load_catsvsdogs_features_resnet18()\n\nX_train, X_test, Y_train, Y_test = train_test_split(\n    X, Y, test_size=0.25, random_state=42)\n\n\nclf = MRC(phi='linear').fit(X_train, Y_train)\nY_pred = clf.predict(X_test)\nerror = np.average(Y_pred != Y_test)\naccuracy = 1 - error\nprint('Cats vs Dogs accuracy error: ' + '%2.2f' % (accuracy * 100) + '%')\ncm = confusion_matrix(Y_test, Y_pred)\ncm_display = ConfusionMatrixDisplay(cm, display_labels=['cat', 'dog']).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Yearbook Dataset\nThe Yearbook dataset which is a publicly-available dataset\nof 37,921 frontal-facing American high school yearbook portraits taken from\n1905 to 2013 labeled by gender.\nWe will perform binary classification. We want to predict\nwhether the person on the image is a man or a woman.\n\nWe wil train an MRC with two different settings: training with the first 2000\nimages and training with the first 16000 images, testing in both cases over\nimages from 16000 to 18000. Note that images are ordered chronologically.\n\nFor coparison purposes, in Kumar, Ma, and Liang (2020)[2], they report\naccuraccies of 75.3\u00b11.6 when\ntraining with \"source\" images (2000 first ones), 76.9\u00b12.1 when training with\n\"target\" images (14000 next ones), 78.9\u00b13.0 when training with both and\n83.8\u00b10.8 when applying their method \"Gradual Self-Training\".\n\n.. seealso:: More information about Yearbook dataset can be found in\n\n              [1] Ginosar, S., Rakelly, K., Sachs, S., Yin, B., & Efros,\n              A. A. (2015). A century of portraits: A visual historical\n              record of american high school yearbooks. In Proceedings of\n              the IEEE International Conference on Computer Vision Workshops\n              (pp. 1-7).\n\n              [2] Kumar, A., Ma, T., & Liang, P. (2020, November).\n              Understanding self-training for gradual domain adaptation.\n              In International Conference on Machine Learning\n              (pp. 5468-5479). PMLR.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, Y = load_yearbook_features_resnet18()\n\nX_train = X[:2000, :]\nY_train = Y[:2000]\nX_test = X[16000:18000, :]\nY_test = Y[16000:18000]\n\nclf = MRC(phi='linear').fit(X_train, Y_train)\nY_pred = clf.predict(X_test)\nerror = np.average(Y_pred != Y_test)\naccuracy = 1 - error\nprint('Yearbook prediction accuracy (2000 training instances): ' +\n      '%2.2f' % (accuracy * 100) + '%')\ncm = confusion_matrix(Y_test, Y_pred)\ncm_display = ConfusionMatrixDisplay(cm, display_labels=['woman', 'man']).plot()\n\nX_train = X[:16000, :]\nY_train = Y[:16000]\nX_test = X[16000:18000, :]\nY_test = Y[16000:18000]\n\nclf = MRC(phi='linear').fit(X_train, Y_train)\nY_pred = clf.predict(X_test)\nerror = np.average(Y_pred != Y_test)\naccuracy = 1 - error\nprint('Yearbook prediction accuracy (16000 training instances): ' +\n      '%2.2f' % (accuracy * 100) + '%')\ncm = confusion_matrix(Y_test, Y_pred)\ncm_display = ConfusionMatrixDisplay(cm, display_labels=['woman', 'man']).plot()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}