
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples\plot_example1.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_example1.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_example1.py:


.. _ex1:

Example: Use of MRC with different settings
===========

Example of using MRC with some of the common classification datasets with
different losses and feature mappings settings. We load the different datasets
and use 10-Fold Cross-Validation to generate the partitions for train and test.
We separate 1 partition each time for testing and use the others for training.
On each iteration we calculate the classification error as well as the upper
and lower bounds for the error. We also calculate the mean training time.

Note that we set the parameter use_cvx=False. In the case of MRC classifiers
this means that we will use nesterov subgradient optimized approach to
perform the optimization.

You can check a more elaborated example in :ref:`ex_comp`.

.. GENERATED FROM PYTHON SOURCE LINES 22-117

.. code-block:: default


    import time

    import numpy as np
    import pandas as pd
    from sklearn import preprocessing
    from sklearn.model_selection import StratifiedKFold

    from MRCpy import MRC
    # Import the datasets
    from MRCpy.datasets import *

    # Data sets
    loaders = [load_mammographic, load_haberman, load_indian_liver,
               load_diabetes, load_credit]
    dataName = ["mammographic", "haberman", "indian_liver",
                "diabetes", "credit"]


    def runMRC(phi, loss):

        results = pd.DataFrame()
        # We fix the random seed to that the stratified kfold performed
        # is the same through the different executions
        random_seed = 0

        # Iterate through each of the dataset and fit the MRC classfier.
        for j, load in enumerate(loaders):

            # Loading the dataset
            X, Y = load()
            r = len(np.unique(Y))
            n, d = X.shape

            clf = MRC(phi=phi, loss=loss,
                      use_cvx=False, max_iters=10000, s=0.3)

            # Generate the partitions of the stratified cross-validation
            cv = StratifiedKFold(n_splits=10, random_state=random_seed,
                                 shuffle=True)

            cvError = list()
            auxTime = 0
            upper = 0
            lower = 0

            # Paired and stratified cross-validation
            for train_index, test_index in cv.split(X, Y):

                X_train, X_test = X[train_index], X[test_index]
                y_train, y_test = Y[train_index], Y[test_index]

                # Normalizing the data
                std_scale = preprocessing.StandardScaler().fit(X_train, y_train)
                X_train = std_scale.transform(X_train)
                X_test = std_scale.transform(X_test)

                # Save start time for computing training time
                startTime = time.time()

                # Train the model and save the upper and lower bounds
                clf.fit(X_train, y_train)
                upper += clf.get_upper_bound()
                lower += clf.get_lower_bound()

                # Save the training time
                auxTime += time.time() - startTime

                # Predict the class for test instances
                y_pred = clf.predict(X_test)

                # Calculate the error made by MRC classificator
                cvError.append(np.average(y_pred != y_test))

            res_mean = np.average(cvError)
            res_std = np.std(cvError)

            # Calculating the mean upper and lower bound and training time
            upper = upper / 10
            lower = lower / 10
            auxTime = auxTime / 10

            results = results.append({'dataset': dataName[j],
                                      'n_samples': '%1.3g' % n,
                                      'n_attributes': '%1.3g' % d,
                                      'n_classes': '%1.3g' % r,
                                      'error': '%1.3g' % res_mean + " +/- " +
                                      '%1.3g' % res_std,
                                      'upper': '%1.3g' % upper,
                                      'lower': '%1.3g' % lower,
                                      'avg_train_time': '%1.3g' % auxTime},
                                     ignore_index=True)
        return results









.. GENERATED FROM PYTHON SOURCE LINES 118-122

.. code-block:: default


    r1 = runMRC(phi='fourier', loss='0-1')
    r1.style.set_caption('Using 0-1 loss and fourier feature mapping')






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style type="text/css">
    </style>
    <table id="T_94569_">
      <caption>Using 0-1 loss and fourier feature mapping</caption>
      <thead>
        <tr>
          <th class="blank level0" >&nbsp;</th>
          <th class="col_heading level0 col0" >dataset</th>
          <th class="col_heading level0 col1" >n_samples</th>
          <th class="col_heading level0 col2" >n_attributes</th>
          <th class="col_heading level0 col3" >n_classes</th>
          <th class="col_heading level0 col4" >error</th>
          <th class="col_heading level0 col5" >upper</th>
          <th class="col_heading level0 col6" >lower</th>
          <th class="col_heading level0 col7" >avg_train_time</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th id="T_94569_level0_row0" class="row_heading level0 row0" >0</th>
          <td id="T_94569_row0_col0" class="data row0 col0" >mammographic</td>
          <td id="T_94569_row0_col1" class="data row0 col1" >961</td>
          <td id="T_94569_row0_col2" class="data row0 col2" >5</td>
          <td id="T_94569_row0_col3" class="data row0 col3" >2</td>
          <td id="T_94569_row0_col4" class="data row0 col4" >0.189 +/- 0.0439</td>
          <td id="T_94569_row0_col5" class="data row0 col5" >0.226</td>
          <td id="T_94569_row0_col6" class="data row0 col6" >0.207</td>
          <td id="T_94569_row0_col7" class="data row0 col7" >1.31</td>
        </tr>
        <tr>
          <th id="T_94569_level0_row1" class="row_heading level0 row1" >1</th>
          <td id="T_94569_row1_col0" class="data row1 col0" >haberman</td>
          <td id="T_94569_row1_col1" class="data row1 col1" >306</td>
          <td id="T_94569_row1_col2" class="data row1 col2" >3</td>
          <td id="T_94569_row1_col3" class="data row1 col3" >2</td>
          <td id="T_94569_row1_col4" class="data row1 col4" >0.271 +/- 0.0171</td>
          <td id="T_94569_row1_col5" class="data row1 col5" >0.263</td>
          <td id="T_94569_row1_col6" class="data row1 col6" >0.238</td>
          <td id="T_94569_row1_col7" class="data row1 col7" >0.992</td>
        </tr>
        <tr>
          <th id="T_94569_level0_row2" class="row_heading level0 row2" >2</th>
          <td id="T_94569_row2_col0" class="data row2 col0" >indian_liver</td>
          <td id="T_94569_row2_col1" class="data row2 col1" >583</td>
          <td id="T_94569_row2_col2" class="data row2 col2" >10</td>
          <td id="T_94569_row2_col3" class="data row2 col3" >2</td>
          <td id="T_94569_row2_col4" class="data row2 col4" >0.286 +/- 0.00722</td>
          <td id="T_94569_row2_col5" class="data row2 col5" >0.292</td>
          <td id="T_94569_row2_col6" class="data row2 col6" >0.28</td>
          <td id="T_94569_row2_col7" class="data row2 col7" >1.39</td>
        </tr>
        <tr>
          <th id="T_94569_level0_row3" class="row_heading level0 row3" >3</th>
          <td id="T_94569_row3_col0" class="data row3 col0" >diabetes</td>
          <td id="T_94569_row3_col1" class="data row3 col1" >768</td>
          <td id="T_94569_row3_col2" class="data row3 col2" >8</td>
          <td id="T_94569_row3_col3" class="data row3 col3" >2</td>
          <td id="T_94569_row3_col4" class="data row3 col4" >0.246 +/- 0.0471</td>
          <td id="T_94569_row3_col5" class="data row3 col5" >0.282</td>
          <td id="T_94569_row3_col6" class="data row3 col6" >0.251</td>
          <td id="T_94569_row3_col7" class="data row3 col7" >1.64</td>
        </tr>
        <tr>
          <th id="T_94569_level0_row4" class="row_heading level0 row4" >4</th>
          <td id="T_94569_row4_col0" class="data row4 col0" >credit</td>
          <td id="T_94569_row4_col1" class="data row4 col1" >690</td>
          <td id="T_94569_row4_col2" class="data row4 col2" >15</td>
          <td id="T_94569_row4_col3" class="data row4 col3" >2</td>
          <td id="T_94569_row4_col4" class="data row4 col4" >0.141 +/- 0.0373</td>
          <td id="T_94569_row4_col5" class="data row4 col5" >0.193</td>
          <td id="T_94569_row4_col6" class="data row4 col6" >0.148</td>
          <td id="T_94569_row4_col7" class="data row4 col7" >1.39</td>
        </tr>
      </tbody>
    </table>

    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 123-126

.. code-block:: default


    r2 = runMRC(phi='fourier', loss='log')
    r2.style.set_caption('Using log loss and fourier feature mapping')





.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style type="text/css">
    </style>
    <table id="T_3a416_">
      <caption>Using log loss and fourier feature mapping</caption>
      <thead>
        <tr>
          <th class="blank level0" >&nbsp;</th>
          <th class="col_heading level0 col0" >dataset</th>
          <th class="col_heading level0 col1" >n_samples</th>
          <th class="col_heading level0 col2" >n_attributes</th>
          <th class="col_heading level0 col3" >n_classes</th>
          <th class="col_heading level0 col4" >error</th>
          <th class="col_heading level0 col5" >upper</th>
          <th class="col_heading level0 col6" >lower</th>
          <th class="col_heading level0 col7" >avg_train_time</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th id="T_3a416_level0_row0" class="row_heading level0 row0" >0</th>
          <td id="T_3a416_row0_col0" class="data row0 col0" >mammographic</td>
          <td id="T_3a416_row0_col1" class="data row0 col1" >961</td>
          <td id="T_3a416_row0_col2" class="data row0 col2" >5</td>
          <td id="T_3a416_row0_col3" class="data row0 col3" >2</td>
          <td id="T_3a416_row0_col4" class="data row0 col4" >0.188 +/- 0.0335</td>
          <td id="T_3a416_row0_col5" class="data row0 col5" >0.535</td>
          <td id="T_3a416_row0_col6" class="data row0 col6" >0.43</td>
          <td id="T_3a416_row0_col7" class="data row0 col7" >3.47</td>
        </tr>
        <tr>
          <th id="T_3a416_level0_row1" class="row_heading level0 row1" >1</th>
          <td id="T_3a416_row1_col0" class="data row1 col0" >haberman</td>
          <td id="T_3a416_row1_col1" class="data row1 col1" >306</td>
          <td id="T_3a416_row1_col2" class="data row1 col2" >3</td>
          <td id="T_3a416_row1_col3" class="data row1 col3" >2</td>
          <td id="T_3a416_row1_col4" class="data row1 col4" >0.265 +/- 0.0241</td>
          <td id="T_3a416_row1_col5" class="data row1 col5" >0.576</td>
          <td id="T_3a416_row1_col6" class="data row1 col6" >0.496</td>
          <td id="T_3a416_row1_col7" class="data row1 col7" >1.91</td>
        </tr>
        <tr>
          <th id="T_3a416_level0_row2" class="row_heading level0 row2" >2</th>
          <td id="T_3a416_row2_col0" class="data row2 col0" >indian_liver</td>
          <td id="T_3a416_row2_col1" class="data row2 col1" >583</td>
          <td id="T_3a416_row2_col2" class="data row2 col2" >10</td>
          <td id="T_3a416_row2_col3" class="data row2 col3" >2</td>
          <td id="T_3a416_row2_col4" class="data row2 col4" >0.286 +/- 0.00722</td>
          <td id="T_3a416_row2_col5" class="data row2 col5" >0.604</td>
          <td id="T_3a416_row2_col6" class="data row2 col6" >0.593</td>
          <td id="T_3a416_row2_col7" class="data row2 col7" >3.12</td>
        </tr>
        <tr>
          <th id="T_3a416_level0_row3" class="row_heading level0 row3" >3</th>
          <td id="T_3a416_row3_col0" class="data row3 col0" >diabetes</td>
          <td id="T_3a416_row3_col1" class="data row3 col1" >768</td>
          <td id="T_3a416_row3_col2" class="data row3 col2" >8</td>
          <td id="T_3a416_row3_col3" class="data row3 col3" >2</td>
          <td id="T_3a416_row3_col4" class="data row3 col4" >0.238 +/- 0.0416</td>
          <td id="T_3a416_row3_col5" class="data row3 col5" >0.596</td>
          <td id="T_3a416_row3_col6" class="data row3 col6" >0.515</td>
          <td id="T_3a416_row3_col7" class="data row3 col7" >4.63</td>
        </tr>
        <tr>
          <th id="T_3a416_level0_row4" class="row_heading level0 row4" >4</th>
          <td id="T_3a416_row4_col0" class="data row4 col0" >credit</td>
          <td id="T_3a416_row4_col1" class="data row4 col1" >690</td>
          <td id="T_3a416_row4_col2" class="data row4 col2" >15</td>
          <td id="T_3a416_row4_col3" class="data row4 col3" >2</td>
          <td id="T_3a416_row4_col4" class="data row4 col4" >0.142 +/- 0.0365</td>
          <td id="T_3a416_row4_col5" class="data row4 col5" >0.498</td>
          <td id="T_3a416_row4_col6" class="data row4 col6" >0.376</td>
          <td id="T_3a416_row4_col7" class="data row4 col7" >3.94</td>
        </tr>
      </tbody>
    </table>

    </div>
    <br />
    <br />


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 3 minutes  58.718 seconds)


.. _sphx_glr_download_auto_examples_plot_example1.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_example1.py <plot_example1.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_example1.ipynb <plot_example1.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
