
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_example2.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_example2.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_example2.py:


.. _ex2:

Example: Use of CMRC with different settings
============================================

Example of using CMRC with some of the common classification datasets with
different losses and feature mappings settings. We load the different datasets
and use 10-Fold Cross-Validation to generate the partitions for train and test.
We separate 1 partition each time for testing and use the others for training.
On each iteration we calculate
the classification error. We also calculate the mean training time.

You can check a more elaborated example in :ref:`ex_comp`.

.. GENERATED FROM PYTHON SOURCE LINES 17-114




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    *** Example (CMRC with the additional     marginal constraints) *** 


    1. Using 0-1 loss and relu feature mapping 


     ############## 
     mammographic n= 961 , d= 5, cardY= 2
     error= : 0.16856743986254294 +/- 0.032164944796554004
     avg_train_time= : 79.13245494365692 secs
     ############## 


     ############## 
     haberman n= 306 , d= 3, cardY= 2
     error= : 0.26526881720430107 +/- 0.043460152215751106
     avg_train_time= : 6.865237593650818 secs
     ############## 


     ############## 
     indian_liver n= 583 , d= 10, cardY= 2
     error= : 0.29336645236703685 +/- 0.030670852514159446
     avg_train_time= : 26.14507086277008 secs
     ############## 


     ############## 
     diabetes n= 768 , d= 8, cardY= 2
     error= : 0.2330997949419002 +/- 0.0418637583604699
     avg_train_time= : 48.58256554603577 secs
     ############## 


     ############## 
     credit n= 690 , d= 15, cardY= 2
     error= : 0.14492753623188406 +/- 0.03995376449881224
     avg_train_time= : 37.77459011077881 secs
     ############## 


    2. Using log loss and relu feature mapping 


     ############## 
     mammographic n= 961 , d= 5, cardY= 2
     error= : 0.1789733676975945 +/- 0.029707428323655517
     avg_train_time= : 10.20141417980194 secs
     ############## 


     ############## 
     haberman n= 306 , d= 3, cardY= 2
     error= : 0.2752688172043011 +/- 0.07597822375160576
     avg_train_time= : 1.9261162996292114 secs
     ############## 


     ############## 
     indian_liver n= 583 , d= 10, cardY= 2
     error= : 0.2862945645821157 +/- 0.037173967181943546
     avg_train_time= : 4.50679624080658 secs
     ############## 


     ############## 
     diabetes n= 768 , d= 8, cardY= 2
     error= : 0.231784005468216 +/- 0.03582418409679763
     avg_train_time= : 6.925230216979981 secs
     ############## 


     ############## 
     credit n= 690 , d= 15, cardY= 2
     error= : 0.14347826086956522 +/- 0.030709594348430565
     avg_train_time= : 5.7290040969848635 secs
     ############## 








|

.. code-block:: default


    import time

    import numpy as np
    from sklearn import preprocessing
    from sklearn.model_selection import StratifiedKFold

    from MRCpy import CMRC
    # Import the datasets
    from MRCpy.datasets import *

    # Data sets
    loaders = [load_mammographic, load_haberman, load_indian_liver,
               load_diabetes, load_credit]
    dataName = ["mammographic", "haberman", "indian_liver",
                "diabetes", "credit"]


    def runCMRC(phi, loss):

        res_mean = np.zeros(len(dataName))
        res_std = np.zeros(len(dataName))

        # We fix the random seed to that the stratified kfold performed
        # is the same through the different executions
        random_seed = 0

        # Iterate through each of the dataset and fit the CMRC classfier.
        for j, load in enumerate(loaders):

            # Loading the dataset
            X, Y = load(return_X_y=True)
            r = len(np.unique(Y))
            n, d = X.shape

            # Print the dataset name
            print(" ############## \n " + dataName[j] + " n= " + str(n) +
                  " , d= " + str(d) + ", cardY= " + str(r))

            # Create the CMRC object initilized with the corresponding parameters
            clf = CMRC(phi=phi, loss=loss, use_cvx=True,
                       solver='MOSEK', max_iters=10000, s=0.3)

            # Generate the partitions of the stratified cross-validation
            cv = StratifiedKFold(n_splits=10, random_state=random_seed,
                                 shuffle=True)

            cvError = list()
            auxTime = 0

            # Paired and stratified cross-validation
            for train_index, test_index in cv.split(X, Y):

                X_train, X_test = X[train_index], X[test_index]
                y_train, y_test = Y[train_index], Y[test_index]

                # Normalizing the data
                std_scale = preprocessing.StandardScaler().fit(X_train, y_train)
                X_train = std_scale.transform(X_train)
                X_test = std_scale.transform(X_test)

                # Save start time for computing training time
                startTime = time.time()

                # Train the model
                clf.fit(X_train, y_train)

                # Save the training time
                auxTime += time.time() - startTime

                # Predict the class for test instances
                y_pred = clf.predict(X_test)

                # Calculate the error made by CMRC classificator
                cvError.append(np.average(y_pred != y_test))

            res_mean[j] = np.average(cvError)
            res_std[j] = np.std(cvError)

            # Calculating the mean training time
            auxTime = auxTime / 10

            print(" error= " + ": " + str(res_mean[j]) + " +/- " +
                  str(res_std[j]) + "\n avg_train_time= " + ": " +
                  str(auxTime) + ' secs' + "\n ############## \n\n")


    if __name__ == '__main__':

        print('*** Example (CMRC with the additional\
         marginal constraints) *** \n\n')

        print('1. Using 0-1 loss and relu feature mapping \n\n')
        runCMRC(phi='relu', loss='0-1')

        print('2. Using log loss and relu feature mapping \n\n')
        runCMRC(phi='relu', loss='log')


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 37 minutes  58.496 seconds)


.. _sphx_glr_download_auto_examples_plot_example2.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_example2.py <plot_example2.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_example2.ipynb <plot_example2.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
