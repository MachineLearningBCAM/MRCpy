{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Example: Use of CMRC with different settings\n\nExample of using CMRC with some of the common classification datasets with\ndifferent losses and feature mappings settings. We load the different datasets\nand use 10-Fold Cross-Validation to generate the partitions for train and test.\nWe separate 1 partition each time for testing and use the others for training.\nOn each iteration we calculate\nthe classification error. We also calculate the mean training time.\n\nNote that we set the parameter use_cvx=False. In the case of CMRC classifiers\nand random fourier feature mapping this means that we will use Stochastic\nGradient Descent (SGD) approach to perform the optimization.\n\nYou can check a more elaborated example in `ex_comp`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom MRCpy import CMRC\n# Import the datasets\nfrom MRCpy.datasets import *\n\n# Data sets\nloaders = [load_mammographic, load_haberman, load_indian_liver,\n           load_diabetes, load_credit]\ndataName = [\"mammographic\", \"haberman\", \"indian_liver\",\n            \"diabetes\", \"credit\"]\n\n\ndef runCMRC(phi, loss):\n    results = pd.DataFrame()\n    res_mean = np.zeros(len(dataName))\n    res_std = np.zeros(len(dataName))\n\n    # We fix the random seed to that the stratified kfold performed\n    # is the same through the different executions\n    random_seed = 0\n\n    # Iterate through each of the dataset and fit the CMRC classfier.\n    for j, load in enumerate(loaders):\n\n        # Loading the dataset\n        X, Y = load()\n        r = len(np.unique(Y))\n        n, d = X.shape\n\n        # Create the CMRC object initilized with the corresponding parameters\n        clf = CMRC(phi=phi, loss=loss, use_cvx=False, s=0.3)\n\n        # Generate the partitions of the stratified cross-validation\n        cv = StratifiedKFold(n_splits=10, random_state=random_seed,\n                             shuffle=True)\n\n        cvError = list()\n        auxTime = 0\n\n        # Paired and stratified cross-validation\n        for train_index, test_index in cv.split(X, Y):\n\n            X_train, X_test = X[train_index], X[test_index]\n            y_train, y_test = Y[train_index], Y[test_index]\n\n            # Normalizing the data\n            std_scale = preprocessing.StandardScaler().fit(X_train, y_train)\n            X_train = std_scale.transform(X_train)\n            X_test = std_scale.transform(X_test)\n\n            # Save start time for computing training time\n            startTime = time.time()\n\n            # Train the model\n            clf.fit(X_train, y_train)\n\n            # Save the training time\n            auxTime += time.time() - startTime\n\n            # Predict the class for test instances\n            y_pred = clf.predict(X_test)\n\n            # Calculate the error made by CMRC classificator\n            cvError.append(np.average(y_pred != y_test))\n\n        res_mean = np.average(cvError)\n        res_std = np.std(cvError)\n\n        # Calculating the mean training time\n        auxTime = auxTime / 10\n\n        results = results.append({'dataset': dataName[j],\n                                  'n_samples': '%1.3g' % n,\n                                  'n_attributes': '%1.3g' % d,\n                                  'n_classes': '%1.3g' % r,\n                                  'error': '%1.3g' % res_mean + \" +/- \" +\n                                  '%1.3g' % res_std,\n                                  'avg_train_time': '%1.3g' % auxTime},\n                                 ignore_index=True)\n    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "r1 = runCMRC(phi='fourier', loss='0-1')\nr1.style.set_caption('Using 0-1 loss and fourier feature mapping')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "r2 = runCMRC(phi='fourier', loss='log')\nr2.style.set_caption('Using log loss and fourier feature mapping')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}