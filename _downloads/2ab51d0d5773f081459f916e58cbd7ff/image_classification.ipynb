{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# SyntaxError\n\nExample script with invalid Python syntax\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n\"\"\"\n.. _feature_mrc:\n\nComputer vision: Image Classification using extracted features\n===============================================================\n\nIn this example we will use a features extracted from different sets of images\nusing pretrained neural networks, as explained in :ref:`Computer vision: Feature\nextraction for image classification <featureextraction>`_\n\nWe will use image features correponding to a set of training images to train an\nMRC model to then predict the class of a set of test images using their\ncorreponding extracted features.\n\"\"\"\n\n\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom MRCpy import MRC\nfrom MRCpy.datasets import load_catsvsdogs_features_resnet18,\n                            load_yearbook_features_resnet18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cats vs Dogs Dataset\nCats vs dogs dataset is a database of 23262 RGB cats\nand dogs images released by Microsoft for the Asirra captcha (`homepage\n<https://www.microsoft.com/en-us/download/details.aspx?id=54765>`_).\nCats are labeled by 0 and dogs by 1 and there are 11658 and 11604 images\nof each class, respectively. We are using the features extracted using\na pretrained ResNet18 netowork over ImageNet.\n\nFor comparison purposes, in this tutorial they obtain accuracy of 97% for\nthis task using a pretrained VGG16 network together with some more deep\nneural layers. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, Y = load_catsvsdogs_features_resnet18()\n\nX_train, X_test, Y_train, Y_test = train_test_split(\n  X, Y, test_size=0.25, random_state=42)\n\n\nclf = MRC(phi='linear').fit(X_train, Y_train)\nY_pred = clf.predict(X_test)\nerror = np.average(Y_pred!=Y_test)\nprint('Cats vs Dogs accuracy error: ' + str(1 - error))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Yearbook Dataset\nThe Yearbook dataset which is a publicly-available dataset\nof 37,921 frontal-facing American high school yearbook portraits taken from\n1905 to 2013 labeled by gender.\nWe will perform binary classification. We want to predict\nwhether the person on the image is a man or a woman.\n\nWe wil train an MRC with two different settings: training with the first 2000\nimages and training with the first 16000 images, testing in both cases over\nimages from 16000 to 18000. Note that images are ordered chronologically.\n\nFor coparison purposes, in Kumar, Ma, and Liang (2020)[2], they report\naccuraccies of 75.3\u00b11.6 when\ntraining with \"source\" images (2000 first ones), 76.9\u00b12.1 when training with\n\"target\" images (14000 next ones), 78.9\u00b13.0 when training with both and\n83.8\u00b10.8 when applying their method \"Gradual Self-Training.l\"\n.. seealso:: More information about Yearbook dataset can be found in\n\n              [1] Ginosar, S., Rakelly, K., Sachs, S., Yin, B., & Efros,\n              A. A. (2015). A century of portraits: A visual historical\n              record of american high school yearbooks. In Proceedings of\n              the IEEE International Conference on Computer Vision Workshops\n              (pp. 1-7).\n\n              [2] Kumar, A., Ma, T., & Liang, P. (2020, November).\n              Understanding self-training for gradual domain adaptation.\n              In International Conference on Machine Learning\n              (pp. 5468-5479). PMLR.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X, Y = load_yearbook_features_resnet18()\n\nX_train = X[:2000,:]\nY_train = Y[:2000]\nX_test = X[16000:18000,:]\nY_test = Y[16000:18000]\n\nclf = MRC(phi='linear').fit(X_train, Y_train)\nY_pred = clf.predict(X_test)\nerror = np.average(Y_pred!=Y_test)\nprint('Yearbook prediction accuracy (2000 training instances): ' +\n    str(1 - error))\n\nX_train = X[:16000,:]\nY_train = Y[:16000]\nX_test = X[16000:18000,:]\nY_test = Y[16000:18000]\n\nclf = MRC(phi='linear').fit(X_train, Y_train)\nY_pred = clf.predict(X_test)\nerror = np.average(Y_pred!=Y_test)\nprint('Yearbook prediction accuracy (16000 training instances): ' +\n    str(1 - error))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}