{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Example of using CMRC with some of the common classification datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom MRCpy import CMRC\n# Import the datasets\nfrom MRCpy.datasets import *\n\n# Data sets\nloaders = [load_mammographic, load_haberman, load_indian_liver,\n           load_diabetes, load_credit]\ndataName = [\"mammographic\", \"haberman\", \"indian_liver\", \"diabetes\", \"credit\"]\n\n\ndef runCMRC(phi, loss):\n\n    random_seed = 0\n    res_mean = np.zeros(len(dataName))\n    res_std = np.zeros(len(dataName))\n    np.random.seed(random_seed)\n\n    # Iterate through each of the dataset and fit the MRC classfier.\n    for j, load in enumerate(loaders):\n\n        # Loading the dataset\n        X, Y = load(return_X_y=True)\n        r = len(np.unique(Y))\n        n, d = X.shape\n\n        # Print the dataset name\n        print(\" ############## \\n\" + dataName[j] + \" n= \" + str(n) +\n              \" , d= \" + str(d) + \", cardY= \" + str(r))\n\n        clf = CMRC(phi=phi, loss=loss, use_cvx=True,\n                   solver='MOSEK', max_iters=10000, s=0.3)\n\n        # Generate the partitions of the stratified cross-validation\n        cv = StratifiedKFold(n_splits=10, random_state=random_seed,\n                             shuffle=True)\n\n        np.random.seed(random_seed)\n        cvError = list()\n        auxTime = 0\n\n        # Paired and stratified cross-validation\n        for train_index, test_index in cv.split(X, Y):\n\n            X_train, X_test = X[train_index], X[test_index]\n            y_train, y_test = Y[train_index], Y[test_index]\n\n            # Normalizing the data\n            std_scale = preprocessing.StandardScaler().fit(X_train, y_train)\n            X_train = std_scale.transform(X_train)\n            X_test = std_scale.transform(X_test)\n\n            # Save start time for computing training time\n            startTime = time.time()\n\n            clf.fit(X_train, y_train)\n\n            # Calculate the training time\n            auxTime += time.time() - startTime\n\n            y_pred = clf.predict(X_test)\n\n            cvError.append(np.average(y_pred != y_test))\n\n        res_mean[j] = np.average(cvError)\n        res_std[j] = np.std(cvError)\n\n        print(\" error= \" + \":\\t\" + str(res_mean[j]) + \"\\t+/-\\t\" +\n              str(res_std[j]) + \"\\navg_train_time= \" + \":\\t\" +\n              str(auxTime / 10) + ' secs' + \"\\n ############## \\n\\n\\n\")\n\n\nif __name__ == '__main__':\n\n    print('******************** \\\n          Example 2 (CMRC with the additional marginal constraints) \\\n          ********************** \\n\\n')\n\n    print('\\t\\t 1. Using 0-1 loss and relu feature mapping \\n\\n')\n    runCMRC(phi='relu', loss='0-1')\n\n    print('\\t\\t 2. Using log loss and relu feature mapping \\n\\n')\n    runCMRC(phi='relu', loss='log')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}